"use strict";(self.webpackChunktaichi_js_com=self.webpackChunktaichi_js_com||[]).push([[1477],{10:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"intro","metadata":{"permalink":"/blog/intro","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2023-04-18-intro.md","source":"@site/blog/2023-04-18-intro.md","title":"taichi.js: WebGPU Programming for N00bs","description":"As a computer graphics and programming languages geek, I am delighted to have found myself working on several GPU compilers in the past 2 years. This began in 2021 when I started to contribute to taichi, a python library that compiles python functions into GPU kernels in CUDA, Metal, or Vulkan. Later on, I joined Meta and started worked on SparkSL, which is the shader language that powers cross-platform GPU programming for AR effects in Instagram and Facebook. Aside from personal pleasure, I have always believed, or at least hoped, that these frameworks are actually quite useful -- they make GPU programming more accessible to non-experts, empowering people to create fasnicating graphics contents without having to master complex GPU concepts.","date":"2023-04-18T00:00:00.000Z","formattedDate":"April 18, 2023","tags":[{"label":"hola","permalink":"/blog/tags/hola"},{"label":"docusaurus","permalink":"/blog/tags/docusaurus"}],"readingTime":12.805,"hasTruncateMarker":false,"authors":[{"name":"Dunfan Lu","title":"Opinions are my own.","url":"https://github.com/AmesingFlank","image_url":"https://github.com/AmesingFlank.png","imageURL":"https://github.com/AmesingFlank.png"}],"frontMatter":{"slug":"intro","title":"taichi.js: WebGPU Programming for N00bs","authors":{"name":"Dunfan Lu","title":"Opinions are my own.","url":"https://github.com/AmesingFlank","image_url":"https://github.com/AmesingFlank.png","imageURL":"https://github.com/AmesingFlank.png"},"tags":["hola","docusaurus"]},"nextItem":{"title":"Welcome","permalink":"/blog/welcome"}},"content":"As a computer graphics and programming languages geek, I am delighted to have found myself working on several GPU compilers in the past 2 years. This began in 2021 when I started to contribute to [`taichi`](https://github.com/taichi-dev/taichi), a python library that compiles python functions into GPU kernels in CUDA, Metal, or Vulkan. Later on, I joined Meta and started worked on [`SparkSL`](https://sparkar.facebook.com/ar-studio/learn/sparksl/sparksl-overview/), which is the shader language that powers cross-platform GPU programming for AR effects in Instagram and Facebook. Aside from personal pleasure, I have always believed, or at least hoped, that these frameworks are actually quite useful -- they make GPU programming more accessible to non-experts, empowering people to create fasnicating graphics contents without having to master complex GPU concepts.\\n\\n\\nIn my latest installment of compilers, I turned my eyes to WebGPU -- the next-generation graphics API for the web. WebGPU promises to bring high-perfrmance graphics via low CPU overhead and explicit GPU control, aligning with the trend started by Vulkan and D3D12 some 7 years ago. Just like Vulkan, the performance benefits of WebGPU comes at the cost of a steep learning curve. Although I\'m confident that this won\'t stop talented programmers around the world from building amazing contents with WebGPU, I wanted to provide people with a way to play with WebGPU without having to confront its complexity. This is how `taichi.js` came to be. \\n\\n\\nUnder the `taichi.js` programming model, programmers don\'t have to reason about WebGPU concepts such as devices, command queues, bind groups, etc. Instead, they write plain Javascript functions, and the compiler translates those functions into WebGPU compute or render pipelines. This means that anyone can write WebGPU code via `taichi.js`, as long as they are familar with basic Javascript syntax. \\n\\nThe remainder of this article will demonstrate the programming model of `taichi.js` via a \\"Game of Life\\" program. As you will see, with less than 100 lines of code, we will create an fully parallel WebGPU program, containing 3 GPU compute pipelines plus a render pipeline. The full source code of the demo can be found [here](https://github.com/AmesingFlank/taichi.js/blob/master/examples/game-of-life/index.js), and if you want to play with the code without having to set-up any local environments, go to [this page](https://stackblitz.com/edit/taichi-js-game-of-life?file=index.js). \\n\\n## The Game\\n\\nThe Game of Life is a classic example of a cellular automaton, a system of cells that evolve over time according to simple rules. It was invented by the mathematician John Conway in 1970 and has since become a favorite of computer scientists and mathematicians alike. The game is played on a two-dimensional grid, where each cell can be either alive or dead. The rules for the game are simple: \\n* if a living cell has fewer than two or more than three living neighbors, it dies\\n* if a dead cell has exactly three living neighbors, it becomes alive. \\n\\nDespite its simplicity, the Game of Life can exhibit surprising behavior. Starting from any random initial state, the game often converges to a state where a few patterns are dominant, as if these are \\"species\\" which survived through evolution.\\n\\n## Simulation\\n\\nLet\'s dive into the Game of Life implementation using `taichi.js`. To begin with, we import the `taichi.js` library under the shorthand `ti`, and define an async `main()` function which will contain all of our logic. Within `main()`, we begin by calling `ti.init()`, which initializes the library and its WebGPU contexts.  \\n```js\\nimport * as ti from \\"path/to/taichi.js\\"\\n\\nlet main = async () => {\\n    await ti.init();\\n\\n    ...\\n};\\n\\nmain()\\n```\\n\\nFollowing `ti.init()`, let\'s define the data structures needed by the \\"Game of Life\\" simulation:\\n```js\\n    let N = 128;\\n\\n    let liveness = ti.field(ti.i32, [N, N])\\n    let numNeighbors = ti.field(ti.i32, [N, N])\\n\\n    ti.addToKernelScope({ N, liveness, numNeighbors });\\n```\\nHere, we defined two variables, `liveness` and `numNeighbors`, both of which are `ti.field`s. In `taichi.js`, a \\"field\\" is essentially an n-dimensional array, whose dimensionality is provided in the 2nd argument to `ti.field()`. The element type of the array is defined in the first argument. In this case, we have `ti.i32`, indicating 32-bit integters. However, field elements may also be other more compelx types, including vectors, matrices, and even structures.\\n\\nThe next line of code, `ti.addToKernelScope({...})`, ensures that the variables `N`, `liveness`, and `numNeighbors` are visible in `taichi.js` \\"kernel\\"s, which are GPU compute and/or render pipelines, defined in the form of Javascript functions. As an example, the following `init` kernel is used to populate our grid cells with initial liveness vales, where each cell has a 20% chance of being alive initially:\\n\\n```js\\n    let init = ti.kernel(() => {\\n        for (let I of ti.ndrange(N, N)) {\\n            liveness[I] = 0\\n            let f = ti.random()\\n            if (f < 0.2) {\\n                liveness[I] = 1\\n            }\\n        }\\n    })\\n    init()\\n```\\nThe `init()` kernel is created by calling `ti.kernel()` with a Javascript lambda as the argument. Under the hood, `taichi.js` will look at the Javascript string represenation of this lambda, and compile its logic into WebGPU code. Here, the lambda contains a `for`-loop, whose loop index `I` iterates through `ti.ndrange(N, N)`. This means that `I` will take `N`x`N` different values, ranging from `[0, 0]` to `[N-1, N-1]`.\\n\\nHere comes the magical part -- in `taichi.js`, all the top-level `for`-loops in the kernel will be parallelized. More specifically, for each possible value of the loop index, `taichi.js` will allocate one WebGPU compute shader thread to execute it. In this case, we dedicate one GPU thread to each cell in our \\"Game of Life\\" simulation, initializing it to a random liveness state. You\'ll notice that the randomness comes from a `ti.random()` function, this is one of the the many functions provided in the `taichi.js` library for kernel use. For a fuller list of these built-in utilities, I refer you to the `taichi.js` documentation.\\n\\nHaving created the initial state of the game, let\'s move on to define how the game evolves. These are the two `taichi.js` kernels defining this evolution:\\n```js\\n    let countNeighbors = ti.kernel(() => {\\n        for (let I of ti.ndrange(N, N)) {\\n            let neighbors = 0\\n            for (let delta of ti.ndrange(3, 3)) {\\n                let J = (I + delta - 1) % N\\n                if ((J.x != I.x || J.y != I.y) && liveness[J] == 1) {\\n                    neighbors = neighbors + 1;\\n                }\\n            }\\n            numNeighbors[I] = neighbors\\n        }\\n    });\\n    let updateLiveness = ti.kernel(() => {\\n        for (let I of ti.ndrange(N, N)) {\\n            let neighbors = numNeighbors[I]\\n            if (liveness[I] == 1) {\\n                if (neighbors < 2 || neighbors > 3) {\\n                    liveness[I] = 0;\\n                }\\n            }\\n            else {\\n                if (neighbors == 3) {\\n                    liveness[I] = 1;\\n                }\\n            }\\n        }\\n    })\\n```\\nSame as the `init()` kernel we saw before, these two kernels also have top-level `for` loops iterating over every grid cell, which are parallelized by the compiler. In `countNeighbors()`, for each cell, we look at the 8 neighboring cells, and count how many of these neighbors are \\"alive\\". The amount of live neighbors are stored into the `numNeighbors` field. Notice that when iterating through neighbors, the loop `for (let delta of ti.ndrange(3, 3)) {...}` is not parallelized, because it is not a top-level loop.  The loop index `delta` ranges from `[0, 0]` to `[2, 2]`, and is used to offset the original cell index `I`. We avoid out-of-bounds accesses by taking a modulo on `N`. (For the topologically-inclined reader, this essentially means the game has toroidal boundary conditions).\\n\\nHaving counted the amount of neighbors for each cell, we move on to update the their liveness states in the `updateLiveness()` kernel. This is simple matter of reading the liveness state of each cell and its current amount of live neighbors, and writing back a new liveness value according to the rules of the game. As usual, this process applies to all cells in parallel.\\n\\nThis essentially concludes the implementation of the game\'s simulation logic. Next up, we will see how to define a WebGPU render pipeline to draw the game\'s evolution onto a webpage.\\n\\n\\n## Rendering\\nWriting rendering code in `taichi.js` is slightly more involved than writing general-purpose compute kernels, and it does require some understanding of vertex shaders, fragment shaders, and rasterization pipelines in general. However, you will find that the simple programming model of `taichi.js` makes these concepts extremely easy to work with and reason about.\\n\\n\\nBefore drawing anything, we need access to a piece of canvas that we are drawing onto. Assuming that a canvas named `result_canvas` exists in the HTML, the following lines of code creates a `ti.CanvasTexture` object, which represents a piece of texture that can be rendered onto by a `taichi.js` render pipeline. \\n```js\\n    let htmlCanvas = document.getElementById(\'result_canvas\');\\n    htmlCanvas.width = 512;\\n    htmlCanvas.height = 512;\\n    let renderTarget = ti.canvasTexture(htmlCanvas);\\n```\\nOn our canvas, we will render a square, and we will draw the Game\'s 2D grid onto this square. In GPUs, geometries to be rendered are represented in the form of triangles. In this case, the square that we are trying to render will be represented as two triangles. These two triangles are defined in a `ti.field`, which store the coordiates of each of the 6 vertices of the 2 triangles:\\n```js\\n    let vertices = ti.field(ti.types.vector(ti.f32, 2), [6]);\\n    await vertices.fromArray([\\n        [-1, -1],\\n        [1, -1],\\n        [-1, 1],\\n        [1, -1],\\n        [1, 1],\\n        [-1, 1],\\n    ]);\\n```\\nAs we did with the `liveness` and `numNeighbors` fields, we need to explicitly declare the `renderTarget` and `vertices` variables to be visible in GPU kernels in `taichi.js`:\\n```js\\n    ti.addToKernelScope({ vertices, renderTarget });\\n```\\nNow we have all the data we need to implement our render pipeline. Here\'s the implementation of the pipeline itself:\\n```js\\n    let render = ti.kernel(() => {\\n        ti.clearColor(renderTarget, [0.0, 0.0, 0.0, 1.0]);\\n        for (let v of ti.inputVertices(vertices)) {\\n            ti.outputPosition([v.x, v.y, 0.0, 1.0]);\\n            ti.outputVertex(v);\\n        }\\n        for (let f of ti.inputFragments()) {\\n            let coord = (f + 1) / 2.0;\\n            let texelIndex = ti.i32(coord * (liveness.dimensions - 1));\\n            let live = ti.f32(liveness[texelIndex]);\\n            ti.outputColor(renderTarget, [live, live, live, 1.0]);\\n        }\\n    });\\n```\\nInside the `render()` kernel, we begin by clearing the `renderTarget` with an all-black color, represented in RGB as `[0.0, 0.0, 0.0, 1.0]`. \\n\\nNext, we define two top-level `for`-loops, which, as you already know, are loops that are parallelzed in WebGPU. However, unlike the previous loops where we iterate over `ti.ndrange` objects, these loops iterate over `ti.inputVertices(vertices)` and `ti.inputFragments()`, respectively. This indicates that these loops will be compiled into WebGPU \\"vertex shaders\\" and \\"fragment shaders\\", which work together as a render pipeline. \\n\\nThe vertex shader has two responsibillities:\\n\\n* For each triangle vertex, compute its final location on the screen (or, more accurately, its \\"Clip Space\\" coordinates). In a 3D rendering pipeline, this will normally involve a bunch of matrix multiplications that transforms the vertex\'s model coordiantes into world space, and then into camera space, and then finally into \\"Clip Space\\". However, for our simple 2D square, the input coordinates of the vertices are already at their correct values in clip space, so we can avoid all of that. All we have to do is append a fixed `z` value of 0.0, and a fixed `w` value of `1.0` (don\'t worry if don\'t know what those are -- not important here!).\\n  ```js\\n            ti.outputPosition([v.x, v.y, 0.0, 1.0]);\\n  ```\\n* For each vertex, generate data to be interpolated and then passed into the fragment shader. In a render pipeline, after the vertex shader is executed, a built-in process known as \\"Rasterization\\" is executed on all the triangles. This is a hardware-accelerated process which computes, for each triangle, which pixels are covered by this triangle. These pixels are also known as \\"fragments\\". For each triangle, the programmer is allowed to generate additional data at each of the 3 vertices, which will be interpolated during the rasterization stage. For each fragment in the pixel, its corresponding fragment shader thread will receive the interpolated values, according to its location within the triangle. \\n\\n  In our case, the fragment shader only needs to know the location of the fragment within the 2D square, so it can fetch the corresponding liveness values of the game. For this purpose, it suffices to pass the 2D vertex coordinate into the rasterizer, which means the fragment shader will receive the interpolated 2D location of the pixel itself:\\n\\n  ```js\\n            ti.outputVertex(v);\\n  ```\\n\\nMoving on to the fragment shader:\\n```js\\n        for (let f of ti.inputFragments()) {\\n            let coord = (f + 1) / 2.0;\\n            let cellIndex = ti.i32(coord * (liveness.dimensions - 1));\\n            let live = ti.f32(liveness[cellIndex]);\\n            ti.outputColor(renderTarget, [live, live, live, 1.0]);\\n        }\\n```\\nThe value `f` is the interpolated pixel location passed-on from the vertex shader. Using this value, the fragment shader will look-up the liveness state of the cell in the game which covers this pixel. This is done by first converting the pixel coordinates `f` in to the `[0, 0] ~ [1, 1]` range, and storing this coordinate into the `coord` variable. This is then multiplied with the dimensions of the `liveness` field, which produces the index of the covering cell. Finally, we fetch the `live` value of this cell, which is 0 if it is dead, and 1 if it is alive. Finally, we output the RGBA value of this pixel onto the `renderTarget`, where the R,G,B compoents are all equal to `live`, and the A component is equal to 1, for full opacity.\\n\\n\\nWith the render pipeline defined, all that\'s left is to put everything together by calling the simulation kernels and the render pipeline every frame:\\n```js\\n    async function frame() {\\n        countNeighbors()\\n        updateLiveness()\\n        await render();\\n        requestAnimationFrame(frame);\\n    }\\n    await frame();\\n```\\nAnd that\'s it! We have completed a WebGPU-based \\"Game of Life\\" implementation in `taichi.js`. If you run the program, you should see the following animation where 128x128 cells evolve for around 1400 generations before converging to a few species of stablized organisms. \\n\\n\\n## Exercises\\nI hope you found this demo interesting! If you did, then I have a few extra exercises and questions that I invite you to experiment with and think about. (Btw, for quickly experimenting with the code, go to [this page](https://stackblitz.com/edit/taichi-js-game-of-life?file=index.js))\\n\\n1. [Easy] Add a FPS counter to the demo! What FPS value can you obtain with the current setting where `N = 128`? Try increasing the value of `N` and see how the framerate changes. Would you be able to write a vanilla Javascript program that obtains this framerate without `taichi.js` or WebGPU?\\n\\n2. [Medium] What would happen if we merge `updateLiveness()` and `updateLiveness()` into a single kernel, and keep the `neighbors` counter as a local variable? Would the program still work correctly always? \\n\\n3. [Hard] In `taichi.js`, a `ti.kernel(..)` always produces an `async` function, regardless of whether it contains compute pipelines or render pipelines. If you have to guess, what is the meaning of this `async`-ness? And what is the meaning of calling `await` on these `async` calls? Finally, in the `frame` function defined above, why did we put `await` only for the `render()` function, but not the other two?\\n\\nThe last 2 questions are especially interesting, as they touches onto the inner workings of the compiler and runtime of the `taichi.js` framework, as well as pinciples of GPU programming. Let me know your answer!\\n\\n\\n## Resources\\nOf course, this Game of Life example only scratches the surface of what you can do with `taichi.js`. From real-time fluid simulations to physically based renderers, there are may other `taichi.js` programs for you to play with, and even more for you to write yourself. For additional examples and learning resources, check out\\n* Github page\\n* Docs\\n* Tutorials\\n* Playground\\n\\n\\nHappy coding!"},{"id":"welcome","metadata":{"permalink":"/blog/welcome","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2021-08-26-welcome/index.md","source":"@site/blog/2021-08-26-welcome/index.md","title":"Welcome","description":"Docusaurus blogging features are powered by the blog plugin.","date":"2021-08-26T00:00:00.000Z","formattedDate":"August 26, 2021","tags":[{"label":"facebook","permalink":"/blog/tags/facebook"},{"label":"hello","permalink":"/blog/tags/hello"},{"label":"docusaurus","permalink":"/blog/tags/docusaurus"}],"readingTime":0.405,"hasTruncateMarker":false,"authors":[{"name":"S\xe9bastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","imageURL":"https://github.com/slorber.png","key":"slorber"},{"name":"Yangshun Tay","title":"Front End Engineer @ Facebook","url":"https://github.com/yangshun","imageURL":"https://github.com/yangshun.png","key":"yangshun"}],"frontMatter":{"slug":"welcome","title":"Welcome","authors":["slorber","yangshun"],"tags":["facebook","hello","docusaurus"]},"prevItem":{"title":"taichi.js: WebGPU Programming for N00bs","permalink":"/blog/intro"},"nextItem":{"title":"MDX Blog Post","permalink":"/blog/mdx-blog-post"}},"content":"[Docusaurus blogging features](https://docusaurus.io/docs/blog) are powered by the [blog plugin](https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog).\\n\\nSimply add Markdown files (or folders) to the `blog` directory.\\n\\nRegular blog authors can be added to `authors.yml`.\\n\\nThe blog post date can be extracted from filenames, such as:\\n\\n- `2019-05-30-welcome.md`\\n- `2019-05-30-welcome/index.md`\\n\\nA blog post folder can be convenient to co-locate blog post images:\\n\\n![Docusaurus Plushie](./docusaurus-plushie-banner.jpeg)\\n\\nThe blog supports tags as well!\\n\\n**And if you don\'t want a blog**: just delete this directory, and use `blog: false` in your Docusaurus config."},{"id":"mdx-blog-post","metadata":{"permalink":"/blog/mdx-blog-post","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2021-08-01-mdx-blog-post.mdx","source":"@site/blog/2021-08-01-mdx-blog-post.mdx","title":"MDX Blog Post","description":"Blog posts support Docusaurus Markdown features, such as MDX.","date":"2021-08-01T00:00:00.000Z","formattedDate":"August 1, 2021","tags":[{"label":"docusaurus","permalink":"/blog/tags/docusaurus"}],"readingTime":0.175,"hasTruncateMarker":false,"authors":[{"name":"S\xe9bastien Lorber","title":"Docusaurus maintainer","url":"https://sebastienlorber.com","imageURL":"https://github.com/slorber.png","key":"slorber"}],"frontMatter":{"slug":"mdx-blog-post","title":"MDX Blog Post","authors":["slorber"],"tags":["docusaurus"]},"prevItem":{"title":"Welcome","permalink":"/blog/welcome"},"nextItem":{"title":"Long Blog Post","permalink":"/blog/long-blog-post"}},"content":"Blog posts support [Docusaurus Markdown features](https://docusaurus.io/docs/markdown-features), such as [MDX](https://mdxjs.com/).\\n\\n:::tip\\n\\nUse the power of React to create interactive blog posts.\\n\\n```js\\n<button onClick={() => alert(\'button clicked!\')}>Click me!</button>\\n```\\n\\n<button onClick={() => alert(\'button clicked!\')}>Click me!</button>\\n\\n:::"},{"id":"long-blog-post","metadata":{"permalink":"/blog/long-blog-post","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2019-05-29-long-blog-post.md","source":"@site/blog/2019-05-29-long-blog-post.md","title":"Long Blog Post","description":"This is the summary of a very long blog post,","date":"2019-05-29T00:00:00.000Z","formattedDate":"May 29, 2019","tags":[{"label":"hello","permalink":"/blog/tags/hello"},{"label":"docusaurus","permalink":"/blog/tags/docusaurus"}],"readingTime":2.05,"hasTruncateMarker":true,"authors":[{"name":"Endilie Yacop Sucipto","title":"Maintainer of Docusaurus","url":"https://github.com/endiliey","imageURL":"https://github.com/endiliey.png","key":"endi"}],"frontMatter":{"slug":"long-blog-post","title":"Long Blog Post","authors":"endi","tags":["hello","docusaurus"]},"prevItem":{"title":"MDX Blog Post","permalink":"/blog/mdx-blog-post"},"nextItem":{"title":"First Blog Post","permalink":"/blog/first-blog-post"}},"content":"This is the summary of a very long blog post,\\n\\nUse a `\x3c!--` `truncate` `--\x3e` comment to limit blog post size in the list view.\\n\\n\x3c!--truncate--\x3e\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\\n\\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"},{"id":"first-blog-post","metadata":{"permalink":"/blog/first-blog-post","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2019-05-28-first-blog-post.md","source":"@site/blog/2019-05-28-first-blog-post.md","title":"First Blog Post","description":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","date":"2019-05-28T00:00:00.000Z","formattedDate":"May 28, 2019","tags":[{"label":"hola","permalink":"/blog/tags/hola"},{"label":"docusaurus","permalink":"/blog/tags/docusaurus"}],"readingTime":0.12,"hasTruncateMarker":false,"authors":[{"name":"Gao Wei","title":"Docusaurus Core Team","url":"https://github.com/wgao19","image_url":"https://github.com/wgao19.png","imageURL":"https://github.com/wgao19.png"}],"frontMatter":{"slug":"first-blog-post","title":"First Blog Post","authors":{"name":"Gao Wei","title":"Docusaurus Core Team","url":"https://github.com/wgao19","image_url":"https://github.com/wgao19.png","imageURL":"https://github.com/wgao19.png"},"tags":["hola","docusaurus"]},"prevItem":{"title":"Long Blog Post","permalink":"/blog/long-blog-post"}},"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"}]}')}}]);