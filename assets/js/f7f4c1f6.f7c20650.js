"use strict";(self.webpackChunktaichi_js_com=self.webpackChunktaichi_js_com||[]).push([[4794],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>k});var a=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},c=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,s=e.parentName,c=o(e,["components","mdxType","originalType","parentName"]),d=p(n),m=i,k=d["".concat(s,".").concat(m)]||d[m]||u[m]||r;return n?a.createElement(k,l(l({ref:t},c),{},{components:n})):a.createElement(k,l({ref:t},c))}));function k(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,l=new Array(r);l[0]=m;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o[d]="string"==typeof e?e:i,l[1]=o;for(var p=2;p<r;p++)l[p]=n[p];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},5021:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>l,default:()=>u,frontMatter:()=>r,metadata:()=>o,toc:()=>p});var a=n(7462),i=(n(7294),n(3905));const r={sidebar_position:2,title:"Kernels"},l=void 0,o={unversionedId:"docs/basics/kernels",id:"docs/basics/kernels",title:"Kernels",description:'In taichi.js, Javascript functions that are compiled into WebGPU shaders are called "kernels". Kernels are created by passing a lambda function to ti.kernel(). For example:',source:"@site/docs/docs/1-basics/2-kernels.md",sourceDirName:"docs/1-basics",slug:"/docs/basics/kernels",permalink:"/docs/docs/basics/kernels",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/docs/1-basics/2-kernels.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2,title:"Kernels"},sidebar:"tutorialSidebar",previous:{title:"Getting Started",permalink:"/docs/docs/basics/getting-started"},next:{title:"Type System",permalink:"/docs/docs/basics/type-system"}},s={},p=[{value:"Kernel Scope",id:"kernel-scope",level:2},{value:"Automatic Parallelization",id:"automatic-parallelization",level:2},{value:"Arguments",id:"arguments",level:2},{value:"Sequential Execution",id:"sequential-execution",level:2},{value:"Asyncness",id:"asyncness",level:2},{value:"Rendering",id:"rendering",level:2}],c={toc:p},d="wrapper";function u(e){let{components:t,...n}=e;return(0,i.kt)(d,(0,a.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"In ",(0,i.kt)("inlineCode",{parentName:"p"},"taichi.js"),', Javascript functions that are compiled into WebGPU shaders are called "kernels". Kernels are created by passing a lambda function to ',(0,i.kt)("inlineCode",{parentName:"p"},"ti.kernel()"),". For example:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-js"},"let increment = ti.kernel(\n    (f) => {\n        return f + 1.0;\n    }\n)\nconsole.log(await increment(42.0)) // logs 43.0\n")),(0,i.kt)("p",null,"Here, ",(0,i.kt)("inlineCode",{parentName:"p"},"taichi.js")," will compile the lambda ",(0,i.kt)("inlineCode",{parentName:"p"},"(f) => {return f + 1.0;}")," into a WebGPU compute shader. Upon calling ",(0,i.kt)("inlineCode",{parentName:"p"},"increment(42.0)"),", the value ",(0,i.kt)("inlineCode",{parentName:"p"},"42.0")," is passed to WebGPU. After the GPU computes the incremented value, it is written back to the CPU to produce the value ",(0,i.kt)("inlineCode",{parentName:"p"},"43.0"),"."),(0,i.kt)("h2",{id:"kernel-scope"},"Kernel Scope"),(0,i.kt)("p",null,"In ",(0,i.kt)("inlineCode",{parentName:"p"},"taichi.js"),", every variable that is accessed in a kernel needs to be explictly declared via ",(0,i.kt)("inlineCode",{parentName:"p"},"ti.addToKernelScope({ ... })"),". As an example, the following kernel adds ",(0,i.kt)("inlineCode",{parentName:"p"},"N")," to its input argument, where ",(0,i.kt)("inlineCode",{parentName:"p"},"N")," is a Javascript-scope variable:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-js"},"let N = 100\nti.addToKernelScope({ N })\nlet addN = ti.kernel(\n    (f) => {\n        return f + N;\n    }\n)\nconsole.log(await addN(42.0)) // logs 142.0\n")),(0,i.kt)("p",null,"If the line ",(0,i.kt)("inlineCode",{parentName:"p"},"ti.addToKernelScope({ N })")," is exluded, then, upon compiling the lambda ",(0,i.kt)("inlineCode",{parentName:"p"},"(f) => { return f + N; }"),", the compiler wouldn't be able to know what ",(0,i.kt)("inlineCode",{parentName:"p"},"N")," is, and will thus throw an error."),(0,i.kt)("admonition",{type:"info"},(0,i.kt)("p",{parentName:"admonition"},"Notice that, in Javascript, the notation ",(0,i.kt)("inlineCode",{parentName:"p"},"{ N }")," is a shorthand for ",(0,i.kt)("inlineCode",{parentName:"p"},"{N: N}"),". So we are actually writing "),(0,i.kt)("pre",{parentName:"admonition"},(0,i.kt)("code",{parentName:"pre"},"ti.addToKernelScope({ N: N })\n")),(0,i.kt)("p",{parentName:"admonition"},"which means we are adding a variable named ",(0,i.kt)("inlineCode",{parentName:"p"},"N")," into the kernel scope, whose value is equal to ",(0,i.kt)("inlineCode",{parentName:"p"},"N"),". We can of course also write "),(0,i.kt)("pre",{parentName:"admonition"},(0,i.kt)("code",{parentName:"pre"},"ti.addToKernelScope({ M: N })\n")),(0,i.kt)("p",{parentName:"admonition"},"and then use ",(0,i.kt)("inlineCode",{parentName:"p"},"M")," within the kernel.")),(0,i.kt)("h2",{id:"automatic-parallelization"},"Automatic Parallelization"),(0,i.kt)("p",null,"The most important feature of kernels is that it automatically parallelizes Javascript code. More specifically, every ",(0,i.kt)("em",{parentName:"p"},"top-level")," ranged ",(0,i.kt)("inlineCode",{parentName:"p"},"for"),"-loop in a kernel is parallelized so that all loop indices are executed in parallel. As an example, the following code segment increments ",(0,i.kt)("inlineCode",{parentName:"p"},"1000")," numbers in parallel on the GPU:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-js"},"let x = ti.field(ti.i32, 1000)\nti.addToKernelScope({ x })\nlet k = ti.kernel(() => {\n    for(let i of ti.range(1000)){\n        x[i] = x[i] + 1\n    }\n}) \nawait k()\n")),(0,i.kt)("p",null,"Here, the variable ",(0,i.kt)("inlineCode",{parentName:"p"},"i")," loops over the range ",(0,i.kt)("inlineCode",{parentName:"p"},"[0, 1000)"),". The compiler recognizes this and automatically distributes these 1000 tasks into 1000 parallel GPU threads. This means that instead of iterating through the members of ",(0,i.kt)("inlineCode",{parentName:"p"},"x")," one-by-one, the kernel will increment every element at the same time."),(0,i.kt)("p",null,"In the previous example, we incremented every element of a 1D array in paralle. If you wish to parallelize tasks over high-dimensional data structures, you can do this in ",(0,i.kt)("inlineCode",{parentName:"p"},"taichi.js")," via ",(0,i.kt)("inlineCode",{parentName:"p"},"ti.ndrange"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-js"},"let x = ti.field(ti.i32, [1000, 1000])\nti.addToKernelScope({ x })\nlet k = ti.kernel(() => {\n    for(let I of ti.ndrange(1000, 1000)){\n        x[I] = x[I] + 1\n    }\n}) \nawait k()\n")),(0,i.kt)("p",null,"In this example, the loop index ",(0,i.kt)("inlineCode",{parentName:"p"},"I")," takes tuple values ranging from ",(0,i.kt)("inlineCode",{parentName:"p"},"[0, 0]")," to ",(0,i.kt)("inlineCode",{parentName:"p"},"[999, 999]"),". The ",(0,i.kt)("inlineCode",{parentName:"p"},"taichi.js")," framework will automatically allocate GPU threads that parallelize over these 1000000 different loop index values."),(0,i.kt)("h2",{id:"arguments"},"Arguments"),(0,i.kt)("p",null,"As shown in the first example in this page, you can pass arguments to kernels. By default, arguments are of the type ",(0,i.kt)("inlineCode",{parentName:"p"},"ti.f32"),". If you wish to pass arguments of other types, you will need to explicitly tell the compiler what the argument types are. As an example, the following kernel takes in a vector, and returns the sum of its components:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-js"},"let f = ti.kernel(\n    {v: ti.types.vector(ti.f32, 3)},\n    (v) => {\n        return v[0] + v[1] + v[2];\n    }\n)\nconsole.log(await f([1.0, 2.0, 3.0])) // logs 6.0\n")),(0,i.kt)("p",null,"Admittedly, this type annotation syntax is a bit unconventional, and arguably cumbersome. However, it is a necessary evil which reconciles the lack of type annotations in Javascript's syntax and the strong type system of WebGPU."),(0,i.kt)("h2",{id:"sequential-execution"},"Sequential Execution"),(0,i.kt)("p",null,"Although the most important feature of kernels is the auto-parallelization of ",(0,i.kt)("inlineCode",{parentName:"p"},"for")," loops, it is sometimes useful for kernels to have a little bit of sequential logic. This is allowed in ",(0,i.kt)("inlineCode",{parentName:"p"},"taichi.js")," by simply putting the logic at the top-level of the kernel function. As an example, in the following kernel, we compute the ",(0,i.kt)("inlineCode",{parentName:"p"},"sin()")," of the input argument ",(0,i.kt)("inlineCode",{parentName:"p"},"t"),", and accumulate the result in every element of a field:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-js"},"let x = ti.field(ti.i32, [1000, 1000])\nti.addToKernelScope({ x })\nlet k = ti.kernel((t) => {\n    let s = ti.sin(t)\n    for(let I of ti.ndrange(1000, 1000)){\n        x[I] = x[I] + s\n    }\n}) \nawait k(0.5)\n")),(0,i.kt)("p",null,"Here, since the ",(0,i.kt)("inlineCode",{parentName:"p"},"ti.sin()")," call exists outside of the ",(0,i.kt)("inlineCode",{parentName:"p"},"for")," loop, it will be executed on a single GPU thread. Notice that its return value, ",(0,i.kt)("inlineCode",{parentName:"p"},"s"),", can still be used freely within the parallel loop. "),(0,i.kt)("h2",{id:"asyncness"},"Asyncness"),(0,i.kt)("p",null,(0,i.kt)("inlineCode",{parentName:"p"},"ti.kernel()")," always returns an async function. Semantically, this means that upon invoking this function, the GPU pipelines will be started, but the function will not wait for GPU operations to complete before returning. Instead, as soon as the GPU started its work, the kernel will return a ",(0,i.kt)("inlineCode",{parentName:"p"},"Promise")," object. An ",(0,i.kt)("inlineCode",{parentName:"p"},"await")," on the promise will ensure the completion of the GPU pipelines and fetch any return values it returns."),(0,i.kt)("h2",{id:"rendering"},"Rendering"),(0,i.kt)("p",null,"In addition to writing compute pipelines with auto-parallelized ",(0,i.kt)("inlineCode",{parentName:"p"},"for"),"-loops, ",(0,i.kt)("inlineCode",{parentName:"p"},"ti.kernel")," can also be used to define WebGPU render pipelines. This will be discussed in details in a later chapter."))}u.isMDXComponent=!0}}]);